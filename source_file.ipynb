{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GPt_bLIgnObS"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mount google drive to facilitate importing of data \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "88efZDoonSlc",
    "outputId": "8230ef6e-b85e-4e29-a9e6-9304e4893df6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing dependencies\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image, ImageEnhance\n",
    "import cv2\n",
    "\n",
    "# Keras functionalities\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D,AveragePooling2D \n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3BIeQx2A0Wp0"
   },
   "outputs": [],
   "source": [
    "#To unzip the training images folder\n",
    "# !unzip 'gdrive/My Drive/grid2019/trainImage.zip'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8El0rvtdnz23"
   },
   "outputs": [],
   "source": [
    "# Loading train.csv and test.csv\n",
    "train = pd.read_csv(\"training.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "leFdTx3Jnk6l"
   },
   "outputs": [],
   "source": [
    "path_train= \"images_train\"\n",
    "path_test= \"images_test\"\n",
    "size=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s8VQ9dY4J1mN"
   },
   "source": [
    "# ** Generating Augmented Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lHjhirtOzIP-"
   },
   "outputs": [],
   "source": [
    "def numfy(train,path,size):   \n",
    "  \"\"\"\n",
    "  Parameters: train = train.csv\n",
    "              path = the path to the folder containing training images\n",
    "  Returns: list of images in the form of numpy array along with their bounding box co-ordinates\n",
    "  \"\"\"\n",
    "  train_names=train.iloc[:,0] \n",
    "  train_coordinates = train.drop(['image_name'],axis= 1) \n",
    "  train_images=[] \n",
    "\n",
    "  for i,name in enumerate(train_names):\n",
    "      for image in glob.glob(os.path.join(path, name)):\n",
    "          img = cv2.imread(image)\n",
    "          img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "          train_images.append(img) \n",
    "\n",
    "  print(\"done\")\n",
    "  \n",
    "  return (train_images),(train_coordinates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fpuHNAsK1Q_t"
   },
   "outputs": [],
   "source": [
    "def flip(image_list,train_df):\n",
    "    \"\"\"\n",
    "    Parameters: image_list = list containing numpy array version of the images,\n",
    "                train_df = train co-ordinates\n",
    "    Returns: flipped image list, flipped bounding-box co-ordinates\n",
    "\n",
    "    \"\"\"    \n",
    "    i = train_df.shape[0]\n",
    "    for a in range(i):\n",
    "        h,w = image_list[a].shape[0],image_list[a].shape[1]\n",
    "        elem = np.random.choice([ 90, 180, 270, 1423, 1234])\n",
    "        x1,x2,y1,y2 = train_df.values[a]\n",
    "        if elem % 10 == 0:\n",
    "            x = x1 - w / 2\n",
    "            y = y1 - h / 2\n",
    "\n",
    "            x1 = w / 2 + x * np.cos(np.deg2rad(elem)) - y * np.sin(np.deg2rad(elem))\n",
    "            y1 = h / 2 + x * np.sin(np.deg2rad(elem)) + y * np.cos(np.deg2rad(elem))\n",
    "\n",
    "            x = x2 - w / 2\n",
    "            y = y2 - h / 2\n",
    "\n",
    "            x2 = w / 2 + x * np.cos(np.deg2rad(elem)) - y * np.sin(np.deg2rad(elem))\n",
    "            y2 = h / 2 + x * np.sin(np.deg2rad(elem)) + y * np.cos(np.deg2rad(elem))\n",
    "\n",
    "            image_list[a] = Image.fromarray(np.uint8(image_list[a]))\n",
    "            image_list[a] = image_list[a].rotate(-elem)\n",
    "            image_list[a] = np.asarray(image_list[a])\n",
    "        else:\n",
    "            if elem == 1423:\n",
    "                image_list[a] = Image.fromarray(np.uint8(image_list[a]))\n",
    "                image_list[a] = image_list[a].transpose(Image.FLIP_TOP_BOTTOM)\n",
    "                image_list[a] = np.asarray(image_list[a])\n",
    "                y1 = h - y1\n",
    "                y2 = h - y2\n",
    "\n",
    "            elif elem == 1234:\n",
    "                image_list[a] = Image.fromarray(np.uint8(image_list[a]))\n",
    "                image_list[a] = image_list[a].transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                image_list[a] = np.asarray(image_list[a])\n",
    "                x1 = w - x1\n",
    "                x2 = w - x2\n",
    "\n",
    "        tmp = x1\n",
    "        x1 = min(x1, x2)\n",
    "        x2 = max(tmp, x2)\n",
    "\n",
    "        tmp = y1\n",
    "        y1 = min(y1, y2)\n",
    "        y2 = max(tmp, y2)\n",
    "\n",
    "        x1 = max(x1, 0)\n",
    "        y1 = max(y1, 0)\n",
    "\n",
    "        y1 = min(y1, h)\n",
    "        x1 = min(x1, w)\n",
    "        y2 = min(y2, h)\n",
    "        x2 = min(x2, w)\n",
    "        train_df.values[a] = x1,x2,y1,y2       \n",
    "    return image_list,train_df\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_gp50DmzIGV"
   },
   "outputs": [],
   "source": [
    "\n",
    "def resize(image_list,train_df,size):\n",
    "    \"\"\"\n",
    "      Parameters: train = train.csv \n",
    "                  path = the path to the folder containing training images\n",
    "                  size = the size to which images are to be resized for the model\n",
    "      Returns: resized image list, resized bounding-box co-ordinates\n",
    "    \"\"\"\n",
    "    i = train_df.shape[0]\n",
    "    for a in range(i):\n",
    "        h,w = image_list[a].shape[0],image_list[a].shape[1]\n",
    "        image_list[a] = cv2.resize(image_list[a], (size, size)) \n",
    "        x1,x2,y1,y2 = train_df.values[a]\n",
    "        x1 = int(x1*size/w)\n",
    "        y1 = int(y1*size/h)\n",
    "        x2 = int(x2*size/w)\n",
    "        y2 = int(y2*size/h)\n",
    "        train_df.values[a] = x1,x2,y1,y2\n",
    "\n",
    "    return image_list,train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8MKoRbaB8Oz9"
   },
   "outputs": [],
   "source": [
    "def normalization(image_list,train_df):\n",
    "    \"\"\"\n",
    "    Parameters: image_list = list containing numpy array version of the images,\n",
    "                train_df = train co-ordinates\n",
    "    Returns: normalized image list, normalized bounding-box co-ordinates\n",
    "    \n",
    "    \"\"\"\n",
    "    i = train_df.shape[0]\n",
    "    for a in range(i):\n",
    "        image_list[a] = cv2.normalize(image_list[a], None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "        \n",
    "    return image_list, train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3-3PIgjsP0jj"
   },
   "outputs": [],
   "source": [
    "def crop(image_list,train_df):\n",
    "    \"\"\"\n",
    "    Parameters: image_list = list containing numpy array version of the images,\n",
    "                train_df = train co-ordinates\n",
    "    Returns: cropped image list, cropped bounding-box co-ordinates\n",
    "    \"\"\"\n",
    "    \n",
    "    i = train_df.shape[0]\n",
    "    for a in range(i):\n",
    "        h,w = image_list[a].shape[0],image_list[a].shape[1]\n",
    "        start_x = np.random.randint(0, high=np.floor(0.15 * w))\n",
    "        stop_x = w - np.random.randint(0, high=np.floor(0.15 * w))\n",
    "        start_y = np.random.randint(0, high=np.floor(0.15 * h))\n",
    "        stop_y = h - np.random.randint(0, high=np.floor(0.15 * h))\n",
    "        \n",
    "        image_list[a] = Image.fromarray(np.uint8(image_list[a]))\n",
    "        image_list[a] = image_list[a].crop((start_x, start_y, stop_x, stop_y))\n",
    "        image_list[a] = np.asarray(image_list[a])\n",
    "        x1,x2,y1,y2 = train_df.values[a]\n",
    "        x1 = max(x1 - start_x, 0)\n",
    "        y1 = max(y1 - start_y, 0)\n",
    "        x2 = min(x2 - start_x, w)\n",
    "        y2 = min(y2 - start_y, h)\n",
    "\n",
    "        if np.abs(x2 - x1) < 5 or np.abs(y2 - y1) < 5: \n",
    "            print(\"\\nWarning: cropped too much (obj width {}, obj height {}, img width {}, img height {})\\n\".format(x2 - x1, y2 - y1, w, h))\n",
    "            \n",
    "        tmp = x1\n",
    "        x1 = min(x1, x2)\n",
    "        x2 = max(tmp, x2)\n",
    "\n",
    "        tmp = y1\n",
    "        y1 = min(y1, y2)\n",
    "        y2 = max(tmp, y2)\n",
    "\n",
    "        x1 = max(x1, 0)\n",
    "        y1 = max(y1, 0)\n",
    "\n",
    "        y1 = min(y1, h)\n",
    "        x1 = min(x1, w)\n",
    "        y2 = min(y2, h)\n",
    "        x2 = min(x2, w)\n",
    "\n",
    "        train_df.values[a] = x1,x2,y1,y2\n",
    "        \n",
    "    return image_list,train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8jAKYy2YSUSr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "\n",
      "Warning: cropped too much (obj width 0, obj height 0, img width 640, img height 480)\n",
      "\n",
      "\n",
      "Warning: cropped too much (obj width 0, obj height 0, img width 640, img height 480)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def augmentation_crop(train,path,size):\n",
    "  \"\"\"\n",
    "  Parameters: train = train.csv \n",
    "              path = the path to the folder containing training images\n",
    "              size = the size to which images are to be resized for the model\n",
    "\n",
    "  Returns: Processed crop images, processed cropped bounding box coordinates\n",
    "  \"\"\"\n",
    "  X_numfy,y_numfy=numfy(train,path,size)\n",
    "#   print(X_numfy[356])\n",
    "#   print(y_numfy.iloc[34])\n",
    "  X_crop,y_crop=crop(X_numfy,y_numfy)\n",
    "#   print(X_crop[356])\n",
    "#   print(y_crop.iloc[34])\n",
    "  X_crop_resize,y_crop_resize=resize(X_crop,y_crop,size)\n",
    "#   print(X_crop_resize[356])\n",
    "#   print(y_crop_resize.iloc[34])\n",
    "  X_aug_crop,y_aug_crop=normalization(X_crop_resize,y_crop_resize)\n",
    "#   print(X_aug_crop[356])\n",
    "#   print(y_aug_crop.iloc[34])\n",
    "  return X_aug_crop,y_aug_crop\n",
    "\n",
    "size=128 \n",
    "X_crop,y_crop=augmentation_crop(train,path_train,size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qGzZtPR96KSV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def augmentation_flip(train,path,size):\n",
    "  \"\"\"\n",
    "  Parameters: train = train.csv \n",
    "              path = the path to the folder containing training images\n",
    "              size = the size to which images are to be resized for the model\n",
    "\n",
    "  Returns: Processed flipped images, processed flipped bounding box coordinates\n",
    "  \"\"\"\n",
    "  X_numfy,y_numfy=numfy(train,path,size)\n",
    "#   print(X_numfy[356])\n",
    "#   print(y_numfy.iloc[34])\n",
    "  X_flip,y_flip=flip(X_numfy,y_numfy)\n",
    "#   print(X_flip[356])\n",
    "#   print(y_flip.iloc[34])\n",
    "  X_flip_resize,y_flip_resize=resize(X_flip,y_flip,size)\n",
    "#   print(X_flip_resize[356])\n",
    "#   print(y_flip_resize.iloc[34])\n",
    "  X_aug_norm,y_aug_norm=normalization(X_flip_resize,y_flip_resize)\n",
    "#   print(X_aug_norm[356])\n",
    "#   print(y_aug_norm.iloc[34])\n",
    "  return X_aug_norm,y_aug_norm\n",
    "\n",
    "size=128\n",
    "X_aug,y_aug=augmentation_flip(train,path_train,size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-a-Bq-4VM3F"
   },
   "outputs": [],
   "source": [
    "# Reshaping the augmented (flipped & cropped) images \n",
    "X_aug=np.reshape(X_aug,(14000,128,128,1))\n",
    "X_crop=np.reshape(X_crop,(14000,128,128,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7la2fG-9So-O"
   },
   "outputs": [],
   "source": [
    "def preprocessing(train,path,size):\n",
    "  \"\"\"\n",
    "  Get X and y for your model after preprocessing the original training images\n",
    "  X = list of 3D Numpy arrays of training images\n",
    "  y = list of bounding box co-ordinates\n",
    "  \n",
    "  -----------------------\n",
    "  Parameters: \n",
    "  1. train (training.csv) dataframe\n",
    "  2. path to the actual training images\n",
    "  3. size = dimensions to which you want to resize your images of the \n",
    "  ------------------------\n",
    "  Return:\n",
    "  X and y as discussed above\n",
    "  \n",
    "  \"\"\"\n",
    "   \n",
    "  train_names=train.iloc[:,0] \n",
    "  train_coordinates = train.drop(['image_name'],axis= 1) \n",
    "  train_images=[] \n",
    "\n",
    "  for i,name in enumerate(train_names):\n",
    "      for image in glob.glob(os.path.join(path, name)):\n",
    "          img = cv2.imread(image)\n",
    "          img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "          w,h = img.shape\n",
    "          x1,x2,y1,y2 = train_coordinates.values[i]\n",
    "          x1 = int(x1*size/h)\n",
    "          y1 = int(y1*size/w)\n",
    "          x2 = int(x2*size/h)\n",
    "          y2 = int(y2*size/w)\n",
    "          train_coordinates.values[i] = x1,x2,y1,y2\n",
    "          img = cv2.resize(img, (size,size))\n",
    "          img= cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "          train_images.append(img) \n",
    "\n",
    "  \n",
    "  return train_images, train_coordinates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PBu06fSySo5I"
   },
   "outputs": [],
   "source": [
    "X,y=preprocessing(train,path_train,size)\n",
    "X=np.reshape(X,(14000,128,128,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UkUFbMzX7IWg",
    "outputId": "6b342b48-9666-43d1-e291-676d4ab7b984"
   },
   "outputs": [],
   "source": [
    "# concatenating original training images, cropped training images and\n",
    "# flipped training images into a new list\n",
    "Xc=np.concatenate((X, X_aug), axis=0)\n",
    "X_new=np.concatenate((Xc,X_crop),axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "d1ISR7YDVmT_",
    "outputId": "1adea32b-c7a6-4d6c-eae8-3af9b9c051dd"
   },
   "outputs": [],
   "source": [
    "# concatenating arrays of bounding box coordinates of original training images, cropped training images and\n",
    "# flipped training images into a new array\n",
    "y_aug_arr=np.array(y_aug)\n",
    "y_arr=np.array(y)\n",
    "yc_arr=np.array(y_crop)\n",
    "yc=np.concatenate((y_arr, y_aug), axis=0)\n",
    "y_new=np.concatenate((yc, yc_arr), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0POCkiqynyLZ"
   },
   "outputs": [],
   "source": [
    "def CNN_Regression():\n",
    "    \"\"\"\n",
    "    Description: Architecture of the CNN-R model \n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(size, size, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  \n",
    "    \n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2048,  activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2048,  activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4))\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False))\n",
    "#     print(model.summary())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "du9GpK8K0Ase"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "42000/42000 [==============================] - 3788s 90ms/step - loss: 179.2348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nEnter 1 to train on 12000 Training and 2000 Validation Images\\nEnter 2 to train entirely on 14000 Training Images\\n\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model=CNN_Regression()\n",
    "model.fit(X_new, y_new, batch_size=32, epochs=60, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Iyc8r4kJt7i-",
    "outputId": "b2774bb1-46b2-49de-9fb9-464e636fb2a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to drive\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Saving Models to drive\n",
    "\n",
    "\"\"\"\n",
    "# model_json = model.to_json()\n",
    "# with open(\"gdrive/My Drive/model128/bestaug128_28k2.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "# # serialize weights to HDF5\n",
    "# model.save_weights(\"gdrive/My Drive/model128/bestaugweights128_28k2.h5\")\n",
    "# print(\"Saved model to drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZVjwa1FGM1g0"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "unzipping test images' folder\n",
    "\"\"\"\n",
    "# !unzip 'gdrive/My Drive/grid2019/testImage.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OrGHx34SmHCj",
    "outputId": "59f37952-5362-4232-d1b0-03bbdd78136c"
   },
   "outputs": [],
   "source": [
    "def preprocessing_test(test,path,size):\n",
    "  \"\"\"\n",
    "  Get X after processing the test images\n",
    "  X = list of 3D Numpy arrays of training images\n",
    "  \n",
    "  \"\"\"\n",
    "  \n",
    "  test_names=test.iloc[:,0] #To get the names of every train image, indexed as per training.csv\n",
    "\n",
    "  \n",
    "  test_images=[] # will contain the 3D numpy version of all the training images 14000 x 224 x 224 x 3\n",
    "\n",
    "  for i,name in enumerate(test_names):\n",
    "#       print(i)\n",
    "      for image in glob.glob(os.path.join(path, name)):\n",
    "          img = cv2.imread(image)\n",
    "          img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "          img = cv2.resize(img, (size,size))\n",
    "          img = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "          test_images.append(img) \n",
    "\n",
    "  \n",
    "  return test_images\n",
    "\n",
    "X_test_final=preprocessing_test(test,path_test,size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1dmnIB8EmQi-"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In the next few lines of code, X_test_final is being reshaped so that it can be fed for\n",
    "predictions using the model we just trained. The predicted bounding boxes are resized to\n",
    "480 X 640 scale and then the results are saved in a csv file as asked in the submission guidelines\n",
    "\"\"\"\n",
    "X_test_final=np.reshape(X_test_final,(12815,128,128,1))\n",
    "y_pred_final = model.predict(np.array(X_test_final))\n",
    "y_pred_final[0]\n",
    "w=480\n",
    "h=640\n",
    "for i in range(y_pred_final.shape[0]):\n",
    "  x1_pred,x2_pred,y1_pred,y2_pred = y_pred_final[i]\n",
    "  x1_pred = (x1_pred*h/size+2)\n",
    "  y1_pred = (y1_pred*w/size+2)\n",
    "  x2_pred = (x2_pred*h/size+2)\n",
    "  y2_pred = (y2_pred*w/size+2)\n",
    "  y_pred_final[i] = x1_pred,x2_pred,y1_pred,y2_pred\n",
    "\n",
    "y_pred_df = pd.DataFrame({'x1':y_pred_final[:,0],'x2':y_pred_final[:,1],'y1':y_pred_final[:,2],'y2':y_pred_final[:,3]})\n",
    "test_names=test.iloc[:,0]\n",
    "y_pred_df.insert(loc=0, column='image_name', value=test_names)\n",
    "y_pred_df.head()\n",
    "y_pred_df.to_csv('Submission.csv', index=False)\n",
    "# !cp bestCF128.csv gdrive/My\\ Drive/\n",
    "# prediction_file=pd.read_csv(\"/content/gdrive/My Drive/bestCF128.csv\")\n",
    "# prediction_file.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WB66LT4RsBIv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "level2_final.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
